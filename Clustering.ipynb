{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Claire\n",
      "[nltk_data]     Danaher\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('C:\\\\WPI\\\\InfoRet\\\\FinalProject\\\\data\\\\reviews_details.csv',encoding = \"ISO-8859-1\")\n",
    "# reviews['listing_id'].value_counts()\n",
    "# vc = reviews['listing_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7441144</td>\n",
       "      <td>52339991</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>45395024</td>\n",
       "      <td>Donato</td>\n",
       "      <td>The host was extremely welcoming and obliging....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7441144</td>\n",
       "      <td>53933755</td>\n",
       "      <td>2015-11-14</td>\n",
       "      <td>36548987</td>\n",
       "      <td>Jason</td>\n",
       "      <td>Nice and easy stay - with good accommodations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7441144</td>\n",
       "      <td>79106284</td>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>39468163</td>\n",
       "      <td>Michael</td>\n",
       "      <td>The host has been very accommodating and helpf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7441144</td>\n",
       "      <td>81799307</td>\n",
       "      <td>2016-06-25</td>\n",
       "      <td>39468163</td>\n",
       "      <td>Michael</td>\n",
       "      <td>It's a great quiet stay.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "1     7441144  52339991  2015-10-28     45395024        Donato   \n",
       "2     7441144  53933755  2015-11-14     36548987         Jason   \n",
       "3     7441144  79106284  2016-06-11     39468163       Michael   \n",
       "4     7441144  81799307  2016-06-25     39468163       Michael   \n",
       "\n",
       "                                            comments  \n",
       "1  The host was extremely welcoming and obliging....  \n",
       "2  Nice and easy stay - with good accommodations ...  \n",
       "3  The host has been very accommodating and helpf...  \n",
       "4                           It's a great quiet stay.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_nonalphanumeric(text):\n",
    "    return re.sub(\"[^a-zA-Z0-9]\",\" \", str(text)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3986"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_listings = reviews.listing_id.unique()\n",
    "len(unique_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=reviews.groupby('listing_id').filter(lambda g: (g.listing_id.size >= 4))\n",
    "reviews = reviews[reviews['listing_id'] != 15041925]\n",
    "reviews = reviews[reviews['listing_id'] !=19102778]\n",
    "\n",
    "unique_listings = reviews.listing_id.unique()\n",
    "len(unique_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews['comments_1'] = reviews['comments'].apply(remove_nonalphanumeric)\n",
    "reviews['tokenized_comments'] = reviews['comments_1'].apply(word_tokenize)\n",
    "stopset = stopwords.words('english') + list(string.punctuation)\n",
    "reviews['stop_comments'] = reviews['tokenized_comments'].apply(lambda x: [item for item in x if item not in stopset])\n",
    "def func(row):\n",
    "    return \" \".join(row)\n",
    "reviews['data'] = reviews['stop_comments'].apply(lambda x: func(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_topics(H,W,feature_names,documents,documents_id,listing_id,words,no_top_words,no_top_documents):\n",
    "    result_list = []\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        message = \" \".join(([feature_names[i]\n",
    "                             for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort(W[:,topic_idx])[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            result = (message,documents_id[doc_index],listing_id[doc_index],documents[doc_index],words[doc_index])\n",
    "            result_list.append(result)\n",
    "\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_top_words = 5\n",
    "no_top_documents = 10\n",
    "result=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7441144\n",
      "term\n",
      "['cable', 'good', 'host', 'neighborhood', 'nice', 'quiet', 'stay', 'tv']\n",
      "12233830\n",
      "term\n",
      "['10', '15', 'able', 'absolutely', 'access', 'accommodating', 'accommodations', 'add', 'advice', 'airbnb', 'airport', 'allston', 'als', 'also', 'always', 'amazing', 'amenities', 'amount', 'ample', 'another', 'answer', 'anyone', 'anything', 'apartment', 'appartement', 'appointed', 'appreciated', 'apt', 'area', 'around', 'arrival', 'arrived', 'asked', 'assist', 'attention', 'attentive', 'available', 'away', 'awesome', 'back', 'balance', 'bars', 'basement', 'bathroom', 'bedroom', 'bedrooms', 'best', 'better', 'beyond', 'bit', 'blocks', 'book', 'boston', 'bottle', 'brand', 'bright', 'bring', 'bus', 'came', 'car', 'challenge', 'charm', 'check', 'checked', 'checking', 'chocolate', 'chocolates', 'city', 'clean', 'cleaning', 'close', 'coffee', 'college', 'come', 'comfortable', 'communicated', 'communication', 'concerns', 'condo', 'convenient', 'cool', 'corner', 'could', 'daily', 'day', 'de', 'definitely', 'delicious', 'described', 'description', 'detail', 'dirt', 'distance', 'downtown', 'drive', 'drove', 'dryer', 'easily', 'easy', 'eat', 'effort', 'en', 'ended', 'enjoyed', 'enough', 'epitome', 'equipped', 'est', 'estee', 'even', 'evening', 'ever', 'every', 'everything', 'exactly', 'expected', 'experience', 'extra', 'extremely', 'family', 'fantastic', 'far', 'fast', 'feel', 'felt', 'fenway', 'find', 'first', 'five', 'floor', 'food', 'found', 'four', 'friendly', 'friends', 'front', 'furnished', 'future', 'game', 'get', 'getting', 'give', 'go', 'good', 'graduation', 'great', 'greeted', 'grocery', 'group', 'guests', 'hair', 'happy', 'harvard', 'helpful', 'hiccup', 'highly', 'home', 'hope', 'hospitality', 'host', 'hostess', 'hosts', 'house', 'however', 'hubway', 'husband', 'ideal', 'incredible', 'incredibly', 'information', 'inside', 'issue', 'kept', 'kind', 'kitchen', 'know', 'late', 'laundry', 'leave', 'left', 'less', 'like', 'links', 'listing', 'little', 'live', 'living', 'local', 'located', 'location', 'long', 'looking', 'lot', 'lots', 'love', 'loved', 'lovely', 'lyft', 'made', 'make', 'making', 'many', 'meet', 'met', 'might', 'min', 'minor', 'minute', 'minutes', 'modern', 'money', 'move', 'much', 'near', 'need', 'needed', 'needs', 'neighborhood', 'new', 'newly', 'next', 'nice', 'nicely', 'night', 'nothing', 'nous', 'ok', 'one', 'others', 'park', 'parking', 'particular', 'parts', 'perfect', 'person', 'personally', 'place', 'places', 'plenty', 'positive', 'possible', 'prepared', 'private', 'problem', 'problems', 'property', 'provided', 'providing', 'public', 'put', 'questions', 'quick', 'quickly', 'quiet', 'quite', 'readily', 'ready', 'real', 'really', 'recently', 'recommend', 'recommendations', 'recommended', 'renovated', 'rental', 'respond', 'responded', 'responsive', 'restaurant', 'restaurants', 'ride', 'right', 'room', 'seamless', 'seemed', 'several', 'shared', 'shop', 'short', 'size', 'sleeping', 'small', 'smaller', 'snacks', 'solve', 'space', 'spacious', 'spot', 'spotless', 'standard', 'station', 'stay', 'stayed', 'staying', 'still', 'stocked', 'stop', 'store', 'street', 'stunning', 'super', 'superb', 'sure', 'surprisingly', 'sweet', 'teenagers', 'ten', 'tenants', 'terrific', 'thank', 'thanks', 'thing', 'things', 'think', 'though', 'thought', 'thoughtful', 'throughout', 'time', 'times', 'tips', 'tons', 'took', 'touch', 'touches', 'town', 'train', 'transportation', 'traveling', 'treats', 'tricky', 'truly', 'tv', 'two', 'uber', 'unit', 'upon', 'us', 'use', 'visit', 'walgreens', 'walk', 'walking', 'want', 'wanted', 'way', 'weekend', 'welcome', 'welcomed', 'welcoming', 'well', 'went', 'whatever', 'wine', 'within', 'wonderful', 'work', 'worked', 'would']\n",
      "14586440\n",
      "term\n",
      "['able', 'absolutely', 'access', 'accessible', 'accommodating', 'air', 'airbnb', 'al', 'also', 'always', 'amazing', 'amenities', 'another', 'anything', 'anywhere', 'apartamento', 'apartment', 'area', 'around', 'arrival', 'arrived', 'asked', 'attractions', 'available', 'awesome', 'back', 'bars', 'bathroom', 'beacon', 'beat', 'beautiful', 'bed', 'bedroom', 'best', 'better', 'big', 'biggest', 'bit', 'block', 'bnb', 'booked', 'boston', 'broken', 'building', 'busy', 'center', 'central', 'change', 'changed', 'charming', 'check', 'checking', 'chose', 'city', 'clean', 'cleaned', 'cleaning', 'cleanliness', 'close', 'closet', 'come', 'comfortable', 'comfy', 'common', 'communicate', 'communicating', 'communication', 'construction', 'could', 'cozy', 'cute', 'day', 'de', 'decided', 'deck', 'decor', 'definitely', 'described', 'difficult', 'distance', 'donuts', 'door', 'doorman', 'downtown', 'due', 'easily', 'easy', 'end', 'es', 'etc', 'even', 'every', 'everything', 'excellent', 'expected', 'exploring', 'fabulous', 'fantastic', 'far', 'fast', 'feel', 'feeling', 'felt', 'first', 'flat', 'flexible', 'floor', 'found', 'freedom', 'fun', 'gardens', 'get', 'go', 'going', 'good', 'gorgeous', 'got', 'great', 'guest', 'hard', 'heart', 'helpful', 'highly', 'hill', 'home', 'host', 'hotels', 'hours', 'house', 'however', 'ideal', 'im', 'incredible', 'instructions', 'issue', 'kitchen', 'know', 'late', 'laundry', 'left', 'less', 'lie', 'like', 'liked', 'linen', 'listing', 'little', 'living', 'located', 'location', 'longer', 'looked', 'looking', 'lot', 'lots', 'loud', 'love', 'lovely', 'made', 'major', 'make', 'makes', 'many', 'matt', 'matthew', 'matthews', 'mattress', 'meet', 'middle', 'might', 'missing', 'morning', 'much', 'multiple', 'near', 'need', 'needed', 'needs', 'negative', 'new', 'next', 'nice', 'nicht', 'night', 'noisy', 'nothing', 'old', 'one', 'others', 'outside', 'overall', 'owner', 'park', 'parking', 'perfect', 'perfectly', 'person', 'photos', 'pictured', 'pictures', 'place', 'popular', 'por', 'positive', 'pretty', 'price', 'problem', 'prompt', 'public', 'putting', 'questions', 'quick', 'quiet', 'quite', 'rather', 'reach', 'really', 'received', 'recommend', 'reservation', 'respond', 'responsive', 'restaurants', 'reviews', 'right', 'roof', 'rooftop', 'room', 'running', 'safe', 'said', 'say', 'see', 'set', 'sheets', 'shops', 'simple', 'since', 'situated', 'size', 'slept', 'small', 'sofa', 'soft', 'space', 'spacious', 'spot', 'state', 'station', 'stay', 'stayed', 'staying', 'still', 'stops', 'store', 'street', 'sunset', 'super', 'sure', 'text', 'texts', 'thank', 'thanks', 'things', 'thought', 'throughout', 'time', 'times', 'top', 'touch', 'tourist', 'towels', 'trail', 'transport', 'trip', 'tv', 'two', 'unfortunately', 'unit', 'us', 'use', 'used', 'value', 'via', 'view', 'views', 'visit', 'walk', 'walkable', 'walking', 'want', 'warm', 'way', 'well', 'went', 'wife', 'wifi', 'within', 'wonderful', 'work', 'worked', 'world', 'would']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Claire Danaher\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Claire Danaher\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Claire Danaher\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15444930\n",
      "term\n",
      "['access', 'apartment', 'area', 'arrived', 'basic', 'bathroom', 'bed', 'boston', 'building', 'cheap', 'check', 'city', 'clean', 'close', 'comfortable', 'could', 'downtown', 'easy', 'equipped', 'every', 'everything', 'floor', 'go', 'good', 'great', 'highly', 'kitchen', 'leave', 'location', 'much', 'need', 'needs', 'next', 'nice', 'night', 'noisy', 'one', 'overall', 'people', 'place', 'property', 'quick', 'recommend', 'shift', 'sketchy', 'sonder', 'sonders', 'space', 'spacious', 'stay', 'stayed', 'table', 'time', 'towels', 'two', 'us', 'use', 'well', 'wonderful', 'would']\n",
      "1596470\n",
      "term\n",
      "['100', 'able', 'absolutely', 'access', 'accommodating', 'accommodations', 'across', 'adding', 'adults', 'advice', 'airbnb', 'alcohol', 'already', 'also', 'amazing', 'amenities', 'answering', 'anybody', 'anyone', 'anything', 'anywhere', 'apartment', 'appliance', 'appliances', 'appointed', 'appreciated', 'areas', 'around', 'arrival', 'attention', 'attractions', 'automated', 'available', 'away', 'awesome', 'back', 'bar', 'bars', 'bathroom', 'bathrooms', 'bay', 'beautiful', 'beds', 'beginning', 'best', 'better', 'beyond', 'big', 'booking', 'bose', 'boston', 'breakfast', 'came', 'car', 'care', 'central', 'centrally', 'check', 'city', 'clean', 'close', 'come', 'comfortable', 'comfortably', 'coming', 'common', 'communicate', 'communication', 'communicative', 'could', 'cozy', 'day', 'days', 'definitely', 'design', 'detail', 'difference', 'dining', 'disappointed', 'distance', 'done', 'door', 'downtown', 'drinks', 'early', 'easily', 'easy', 'eggs', 'end', 'enjoy', 'enjoyed', 'enough', 'ensure', 'entire', 'equipment', 'equipped', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'exceeded', 'excellent', 'expectations', 'experience', 'explore', 'extremely', 'fabulous', 'family', 'fantastic', 'far', 'features', 'feel', 'feeling', 'feels', 'felt', 'find', 'first', 'fit', 'five', 'floors', 'food', 'forward', 'found', 'four', 'fridge', 'friendly', 'front', 'fruit', 'fully', 'gave', 'generous', 'get', 'give', 'giving', 'go', 'going', 'good', 'gorgeous', 'got', 'gourmet', 'grateful', 'great', 'greatly', 'group', 'guests', 'heartbeat', 'heated', 'helpful', 'hesitation', 'high', 'highly', 'home', 'hospitality', 'host', 'hotel', 'house', 'ideal', 'imagine', 'incredible', 'information', 'interior', 'issue', 'kids', 'kitchen', 'la', 'laid', 'larder', 'large', 'like', 'linens', 'living', 'local', 'located', 'location', 'lock', 'long', 'looking', 'looks', 'lot', 'lots', 'love', 'loved', 'lovely', 'luxury', 'made', 'main', 'make', 'makes', 'making', 'many', 'meet', 'met', 'michael', 'micheal', 'might', 'modern', 'much', 'near', 'need', 'needed', 'needs', 'neighborhood', 'netflix', 'new', 'nice', 'nicely', 'nights', 'notch', 'nothing', 'offer', 'one', 'opportunity', 'organized', 'outstanding', 'pantry', 'parking', 'perfect', 'perfection', 'perfectly', 'piano', 'place', 'places', 'pleasure', 'plenty', 'plus', 'property', 'provide', 'provided', 'providing', 'provisioned', 'public', 'quality', 'questions', 'quickly', 'quiet', 'really', 'recommend', 'recommendations', 'recommended', 'relaxing', 'renovated', 'rental', 'reservation', 'responsive', 'restaurants', 'return', 'reviews', 'right', 'room', 'say', 'see', 'service', 'set', 'shopping', 'showed', 'simple', 'sleep', 'small', 'smooth', 'snacks', 'someone', 'sound', 'south', 'space', 'spaces', 'spacious', 'spectacular', 'spot', 'spotlessly', 'staples', 'stars', 'stay', 'stayed', 'staying', 'stocked', 'story', 'street', 'stunning', 'stylish', 'super', 'sure', 'surprise', 'system', 'text', 'thank', 'thanks', 'things', 'think', 'thought', 'thoughtful', 'throughout', 'time', 'tips', 'top', 'tourist', 'towels', 'town', 'townhouse', 'transportation', 'trip', 'truly', 'upscale', 'us', 'use', 'used', 'visit', 'visited', 'visiting', 'wait', 'walk', 'walked', 'walking', 'want', 'wanted', 'warm', 'way', 'week', 'weekend', 'welcome', 'welcoming', 'well', 'whole', 'within', 'wonderful', 'work', 'would', 'yet']\n",
      "8211468\n",
      "term\n",
      "['able', 'accommodating', 'accurate', 'apartment', 'arrival', 'available', 'away', 'back', 'bathroom', 'bay', 'bit', 'blocks', 'boston', 'check', 'checking', 'clean', 'close', 'comfortable', 'convenient', 'copley', 'cozy', 'described', 'distance', 'easy', 'etc', 'even', 'everything', 'exactly', 'good', 'great', 'helpful', 'host', 'issue', 'jonathan', 'let', 'listing', 'located', 'location', 'looks', 'lovely', 'made', 'neighborhood', 'nice', 'part', 'people', 'perfect', 'photos', 'pictures', 'place', 'questions', 'really', 'shops', 'small', 'solve', 'square', 'station', 'stay', 'studio', 'time', 'town', 'train', 'two', 'us', 'value', 'visit', 'walk', 'walking', 'well', 'wonderful', 'would']\n",
      "19824694\n",
      "term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Claire Danaher\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Claire Danaher\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Claire Danaher\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of bounds: 0 <= 1 <= 4, 0 <= 5 <= 4, 1 <= 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ff39f969ba2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlisting_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'term'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtf_feature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_feature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    302\u001b[0m                      row.step in (1, None))):\n\u001b[0;32m    303\u001b[0m                 \u001b[1;31m# col is int or slice with step 1, row is slice with step 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_submatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;31m# row is slice, col is sequence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m_get_submatrix\u001b[1;34m(self, row_slice, col_slice)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0mi0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0mj0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[0mcheck_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m         \u001b[0mcheck_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mcheck_bounds\u001b[1;34m(i0, i1, num)\u001b[0m\n\u001b[0;32m    441\u001b[0m                 raise IndexError(\n\u001b[0;32m    442\u001b[0m                       \u001b[1;34m\"index out of bounds: 0 <= %d <= %d, 0 <= %d <= %d,\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m                       \" %d <= %d\" % (i0, num, i1, num, i0, i1))\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0mi0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of bounds: 0 <= 1 <= 4, 0 <= 5 <= 4, 1 <= 5"
     ]
    }
   ],
   "source": [
    "for each_listing in unique_listings:\n",
    "    print(each_listing)\n",
    "    \n",
    "    listing_reviews=reviews[reviews['listing_id']==each_listing]\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.80, min_df=2, max_features=500)\n",
    "    tf = tf_vectorizer.fit_transform(listing_reviews['data'])\n",
    "    print('term')\n",
    "    tf[1:5]\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    print(tf_feature_names)\n",
    "    lda = LatentDirichletAllocation(n_topics = 5, max_iter = 5,learning_method='online',learning_offset=50., random_state=0).fit(tf)\n",
    "    lda_W = lda.transform(tf)\n",
    "    lda_H = lda.components_\n",
    "    output = display_topics(lda_H,lda_W,tf_feature_names,list(listing_reviews['comments']),list(listing_reviews['id']),list(listing_reviews['listing_id']),list(listing_reviews['data']),no_top_words,no_top_documents)\n",
    "    result += output\n",
    "\n",
    "result_df = pd.DataFrame(result, columns=['Topic','Review_Id','Listing_Id','Documents','Words'])\n",
    "result_df.to_csv(\"Result_entire.csv\",columns=[\"Topic\",\"Review_Id\",\"Listing_Id\",\"Documents\",\"Words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 61)\n",
      "['access', 'apartment', 'area', 'arrived', 'basic', 'bathroom', 'bed', 'boston', 'building', 'cheap', 'check', 'check great', 'check great location', 'city', 'clean', 'clean comfortable', 'close', 'comfortable', 'downtown', 'easy', 'easy check', 'equipped', 'floor', 'good', 'great', 'great location', 'great location easy', 'great place', 'highly', 'kitchen', 'leave', 'location', 'location apartment', 'location easy', 'need', 'needs', 'nice', 'night', 'noisy', 'overall', 'people', 'place', 'property', 'quick', 'recommend', 'shift', 'sketchy', 'sonder', 'sonder place', 'sonders', 'space', 'spacious', 'stay', 'stay boston', 'stayed', 'table', 'time', 'time shift', 'towels', 'use', 'wonderful']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### CONDUCT CLUSTING FOR LISTING 15444930 using TF-IDF\n",
    "\n",
    "listing_reviews=reviews[reviews['listing_id']==15444930]\n",
    "names=listing_reviews['reviewer_name']\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.80, min_df=2, max_features=500, stop_words='english',use_idf=True, ngram_range=(1,4))\n",
    "tfidf_matrix = tf_vectorizer.fit_transform(listing_reviews['data'])\n",
    "print(tfidf_matrix.shape)\n",
    "terms = tf_vectorizer.get_feature_names()\n",
    "print(terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments=listing_reviews['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#uncomment the below to save your model \n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clust = {  'cluster': clusters }\n",
    "\n",
    "frame = pd.DataFrame(clust, index = [clusters] , columns = [ 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5\n",
       "2    5\n",
       "3    4\n",
       "1    3\n",
       "0    3\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['cluster'].value_counts() #number of films per cluster (clusters from 0 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words:\n",
      "comfortable\n",
      "clean comfortable\n",
      "nice\n",
      "bed\n",
      "time\n",
      "shift\n",
      "\n",
      "\n",
      "Cluster 1 words:\n",
      "place\n",
      "great place\n",
      "cheap\n",
      "great\n",
      "needs\n",
      "kitchen\n",
      "\n",
      "\n",
      "Cluster 2 words:\n",
      "recommend\n",
      "apartment\n",
      "time\n",
      "check\n",
      "access\n",
      "clean\n",
      "\n",
      "\n",
      "Cluster 3 words:\n",
      "close\n",
      "stay\n",
      "sonder place\n",
      "place\n",
      "boston\n",
      "wonderful\n",
      "\n",
      "\n",
      "Cluster 4 words:\n",
      "space\n",
      "location\n",
      "apartment\n",
      "great\n",
      "check\n",
      "bed\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\\n\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        print(terms[ind])\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "\n",
    "    \n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster\n",
       "2        2\n",
       "2        2\n",
       "1        1\n",
       "4        4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184    We spent a lovely time in this super well loca...\n",
      "185       Great access and convenient. Would recommend! \n",
      "186                               Great place and cheap.\n",
      "187    It was a good experience. Sonder's team is ver...\n",
      "Name: comments, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(comments[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "\n",
    "linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 20)) # set size\n",
    "ax = dendrogram(linkage_matrix, orientation=\"right\");\n",
    "\n",
    "plt.tick_params(\n",
    "    axis= 'x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off')\n",
    "\n",
    "plt.tight_layout() #show plot with tight layout\n",
    "\n",
    "#uncomment below to save figure\n",
    "plt.savefig('ward_clusters.png', dpi=200) #save figure as ward_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_tfidf_feats(row, features, top_n=10):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        feature     tfidf\n",
      "0          lots  0.249482\n",
      "1       located  0.249482\n",
      "2       tourist  0.249482\n",
      "3       initial  0.249482\n",
      "4   attractions  0.249482\n",
      "5     regarding  0.249482\n",
      "6         major  0.249482\n",
      "7          give  0.249482\n",
      "8          slow  0.219299\n",
      "9    experience  0.219299\n",
      "10      contact  0.219299\n",
      "11        right  0.219299\n",
      "12      process  0.219299\n",
      "13        great  0.209251\n",
      "14          bit  0.197883\n",
      "15      overall  0.197883\n",
      "16        check  0.181272\n",
      "17       access  0.167700\n",
      "18       alicia  0.146284\n",
      "19      newbury  0.146284\n",
      "20       street  0.137516\n",
      "21        place  0.129673\n",
      "22         five  0.000000\n",
      "23         felt  0.000000\n",
      "24         feet  0.000000\n",
      "        feature     tfidf\n",
      "0          like  0.233270\n",
      "1        basics  0.225764\n",
      "2        rental  0.192628\n",
      "3          even  0.172644\n",
      "4        toilet  0.152788\n",
      "5       pillows  0.152788\n",
      "6         paper  0.152788\n",
      "7          help  0.128419\n",
      "8         gives  0.128419\n",
      "9         motel  0.128419\n",
      "10        using  0.128419\n",
      "11     sleeping  0.128419\n",
      "12         fact  0.128419\n",
      "13       pillow  0.128419\n",
      "14   acceptable  0.128419\n",
      "15         full  0.112882\n",
      "16      shampoo  0.112882\n",
      "17  comfortable  0.112882\n",
      "18         make  0.112882\n",
      "19         none  0.112882\n",
      "20       stayed  0.101859\n",
      "21     bathroom  0.101859\n",
      "22        close  0.101859\n",
      "23        hotel  0.101859\n",
      "24        could  0.101859\n"
     ]
    }
   ],
   "source": [
    "\n",
    "row=np.squeeze(xtr[3].toarray())\n",
    "#print(row)\n",
    "x=top_tfidf_feats(row, feature)\n",
    "row=np.squeeze(xtr[7].toarray())\n",
    "y=top_tfidf_feats(row, feature)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAELCAYAAADeNe2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ed10c93978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Authors: Mathew Kallada\n",
    "# License: BSD 3 clause\n",
    "\"\"\"\n",
    "=========================================\n",
    "Plot Hierarachical Clustering Dendrogram \n",
    "=========================================\n",
    "This example plots the corresponding dendrogram of a hierarchical clustering\n",
    "using AgglomerativeClustering and the dendrogram method available in scipy.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "\n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plot_dendrogram(cluster, labels=cluster.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-69f13a296762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlisting_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "print(listing_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
